{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from typing import List, Dict, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from kbc_pul.project_info import data_dir as kbc_pul_data_dir\n",
    "from kbc_pul.experiments_utils.datasets.data_cleaning import clean_triples\n",
    "from kbc_pul.experiments_utils.file_utils import print_file_exists\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Yago Yago3_10 data cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? file exists: /home/joschout/Documents/Repos/KBC-e-metrics/data/yago3_10/cleaned_csv\n",
      "-> True\n",
      "? file exists: /home/joschout/Documents/Repos/KBC-e-metrics/data/yago3_10/original\n",
      "-> True\n"
     ]
    }
   ],
   "source": [
    "dataset_name: str = 'yago3_10'\n",
    "cleaned_data_dir = os.path.join(kbc_pul_data_dir, dataset_name, 'cleaned_csv')\n",
    "original_data_dir = os.path.join(kbc_pul_data_dir, dataset_name, 'original')\n",
    "print_file_exists(cleaned_data_dir)\n",
    "print_file_exists(original_data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "data_partition_sets: List[str] = ['train', 'valid', 'test']\n",
    "\n",
    "original_data_map = dict()\n",
    "column_names: List[str] =[\"E1\", \"Rel\", \"E2\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? file exists: /home/joschout/Documents/Repos/KBC-e-metrics/data/yago3_10/original/train.txt\n",
      "-> True\n",
      "? file exists: /home/joschout/Documents/Repos/KBC-e-metrics/data/yago3_10/original/valid.txt\n",
      "-> True\n",
      "? file exists: /home/joschout/Documents/Repos/KBC-e-metrics/data/yago3_10/original/test.txt\n",
      "-> True\n"
     ]
    }
   ],
   "source": [
    "for dataset_part_name in data_partition_sets:\n",
    "    original_data_part_filename = os.path.join(\n",
    "            original_data_dir,\n",
    "            f\"{dataset_part_name}.txt\"\n",
    "    )\n",
    "    print_file_exists(original_data_part_filename)\n",
    "    original_data_map[dataset_part_name] = pd.read_csv(\n",
    "        original_data_part_filename,\n",
    "        sep=\"\\t\",\n",
    "        header=None, names=column_names\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "                    E1             Rel                          E2\n0               Chatou     isLocatedIn                      France\n1        Boo_Young-tae        playsFor           Yangju_Citizen_FC\n2        Toni_Kuivasto  isAffiliatedTo   Helsingin_Jalkapalloklubi\n3  Josh_Smith_(soccer)        playsFor  Trinity_University_(Texas)\n4       Albrecht_Dürer          diedIn                   Nuremberg",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>E1</th>\n      <th>Rel</th>\n      <th>E2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chatou</td>\n      <td>isLocatedIn</td>\n      <td>France</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Boo_Young-tae</td>\n      <td>playsFor</td>\n      <td>Yangju_Citizen_FC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Toni_Kuivasto</td>\n      <td>isAffiliatedTo</td>\n      <td>Helsingin_Jalkapalloklubi</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Josh_Smith_(soccer)</td>\n      <td>playsFor</td>\n      <td>Trinity_University_(Texas)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albrecht_Dürer</td>\n      <td>diedIn</td>\n      <td>Nuremberg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data_map['train'].head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - (1079040, 3)\n",
      "valid - (5000, 3)\n",
      "test - (5000, 3)\n"
     ]
    }
   ],
   "source": [
    "for data_part in data_partition_sets:\n",
    "    print(f\"{data_part} - {original_data_map[data_part].shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Duplicate detection on the original data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - (0, 3)\n",
      "valid - (0, 3)\n",
      "test - (0, 3)\n"
     ]
    }
   ],
   "source": [
    "for dataset_part_name in data_partition_sets:\n",
    "    original_data_df: pd.DataFrame = original_data_map[dataset_part_name]\n",
    "    duplicate_rows = original_data_df[original_data_df.duplicated()]\n",
    "    print(f\"{dataset_part_name} - {duplicate_rows.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning data, PER dataset part"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning train\n",
      "Writing train to /home/joschout/Documents/Repos/KBC-e-metrics/data/yago3_10/cleaned_csv/train.csv\n",
      "train - (0, 3)\n",
      "Sorting on Object...\n",
      "Sorting on Subject...\n",
      "Sorting on Rel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1079040/1079040 [00:18<00:00, 56934.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning valid\n",
      "Writing valid to /home/joschout/Documents/Repos/KBC-e-metrics/data/yago3_10/cleaned_csv/valid.csv\n",
      "valid - (0, 3)\n",
      "Sorting on Object...\n",
      "Sorting on Subject...\n",
      "Sorting on Rel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 61156.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning test\n",
      "Writing test to /home/joschout/Documents/Repos/KBC-e-metrics/data/yago3_10/cleaned_csv/test.csv\n",
      "test - (0, 3)\n",
      "Sorting on Object...\n",
      "Sorting on Subject...\n",
      "Sorting on Rel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 50031.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delimiter = \"\\t\"\n",
    "reclean = True\n",
    "should_sort: bool = True\n",
    "if reclean:\n",
    "    # for train, test, valid\n",
    "    for dataset_part_name in data_partition_sets:\n",
    "        print(f\"cleaning {dataset_part_name}\")\n",
    "        dataset_part_output_csv_filename: str = os.path.join(\n",
    "            cleaned_data_dir,\n",
    "            f\"{dataset_part_name}.csv\"\n",
    "        )\n",
    "        print(f\"Writing {dataset_part_name} to {dataset_part_output_csv_filename}\")\n",
    "\n",
    "        dataset_part_df = original_data_map[dataset_part_name]\n",
    "        duplicate_rows = dataset_part_df[dataset_part_df.duplicated()]\n",
    "        print(f\"{dataset_part_name} - {duplicate_rows.shape}\")\n",
    "        dataset_part = dataset_part_df.values\n",
    "        clean_triples(\n",
    "            dataset_part=dataset_part,\n",
    "            dataset_part_output_csv_filename=dataset_part_output_csv_filename,\n",
    "            should_sort=should_sort,\n",
    "            separator=delimiter\n",
    "        )\n",
    "print(\"DONE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop any duplicates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning train\n",
      "Length before dropping duplicates: 1079040\n",
      "Length after dropping duplicates: 1078898\n",
      "---\n",
      "Cleaning valid\n",
      "Length before dropping duplicates: 5000\n",
      "Length after dropping duplicates: 5000\n",
      "---\n",
      "Cleaning test\n",
      "Length before dropping duplicates: 5000\n",
      "Length after dropping duplicates: 5000\n",
      "---\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "should_drop_duplicates = True\n",
    "if should_drop_duplicates:\n",
    "    dataset_name: str\n",
    "    for dataset_part_name in data_partition_sets:\n",
    "        print(f\"Cleaning {dataset_part_name}\")\n",
    "        dataset_part_output_csv_filename: str = os.path.join(\n",
    "            cleaned_data_dir,\n",
    "            f\"{dataset_part_name}.csv\"\n",
    "        )\n",
    "\n",
    "        # --- removing inverted relations and duplicates ---\n",
    "        header=[\"E1\", \"Rel\", \"E2\"]\n",
    "        triples_df: pd.DataFrame = pd.read_csv(\n",
    "            dataset_part_output_csv_filename, header=None, names=header,\n",
    "            sep=delimiter\n",
    "        )\n",
    "        # print(f\"Length before dropping inverted relations: {len(triples_df)}\")\n",
    "        # triples_df = triples_df[~triples_df['Rel'].isin(inverted_relations)]\n",
    "        # print(f\"Length after dropping inverted_relations: {len(triples_df)}\")\n",
    "\n",
    "        print(f\"Length before dropping duplicates: {len(triples_df)}\")\n",
    "        triples_df: pd.DataFrame = triples_df.drop_duplicates()\n",
    "        print(f\"Length after dropping duplicates: {len(triples_df)}\")\n",
    "        triples_df.to_csv(\n",
    "            dataset_part_output_csv_filename, header=False, index=False,\n",
    "            sep=delimiter\n",
    "        )\n",
    "        print(\"---\")\n",
    "print(\"DONE\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joschout/anaconda3/envs/KBC-e-metrics/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "dataset_part_output_csv_filename: str = os.path.join(\n",
    "    cleaned_data_dir,\n",
    "    f\"train.csv\"\n",
    ")\n",
    "\n",
    "# --- removing inverted relations and duplicates ---\n",
    "header=[\"E1\", \"Rel\", \"E2\"]\n",
    "triples_df: pd.DataFrame = pd.read_csv(dataset_part_output_csv_filename, header=None, names=header)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(0, 3)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows = triples_df[triples_df.duplicated()]\n",
    "duplicate_rows.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [E1, Rel, E2]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>E1</th>\n      <th>Rel</th>\n      <th>E2</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_rows.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}